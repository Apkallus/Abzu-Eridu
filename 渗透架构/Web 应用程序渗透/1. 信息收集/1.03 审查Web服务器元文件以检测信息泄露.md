# 审查Web服务器元文件以检测信息泄露

## 摘要

通过测试各种元数据文件，以检测web应用程序路径或功能的信息泄露。此外，还可以将蜘蛛、机器人或爬虫避免的目录列表创建为[映射应用程序执行路径]()（信息收集 1.07节）的依赖项。还可以收集其他信息来识别攻击面、技术细节或用于社会工程活动。

## 目标

- 通过分析元数据文件，识别隐藏或混淆的路径与功能。
- 提取并映射其他信息，从而更深入地理解当前系统。

## 方法

```wget```执行的任何操作都可使用```curl```完成。许多动态应用安全测试（DAST）工具，如ZAP和Burp Suite，在其爬虫/蜘蛛功能中包含对这些资源的检查或解析。还可使用各种 Google Dorks 或利用高级搜索功能（如```inurl:```）进行识别。

### 爬虫文件

Web spider、robot或crawler检索一个Web页面，然后递归地遍历超链接以检索更多的Web内容。它们被接受的行为由web根目录下的```robots.txt```文件中的 [Robots排除协议](https://www.robotstxt.org/) 指定。

例如，下面引用了 2025 年 12 月 22 日从 [Bing](https://cn.bing.com/robots.txt) 采集的 ```robots.txt``` 文件的开头部分：

```
User-agent: *
Disallow: /academic/profile
Disallow: /academic/search
Disallow: /account/
Disallow: /aclick
Disallow: /alink
Disallow: /amp/
Allow: /api/maps/
...
```

User-Agent指令指的是特定的网络蜘蛛/机器人/爬虫。例如， 
```User-Agent: Googlebot``` 指来自谷歌的蜘蛛，而 
```User-Agent: bingbot``` 指来自Microsoft的爬虫。 
```User-Agent: *``` 适用于所有网络蜘蛛/机器人/爬虫。

```Disallow``` 指令指定哪些资源对蜘蛛/机器人/爬虫禁止。在上面的例子中，以下内容是被禁止的：

```
...
Disallow: /academic/profile
Disallow: /academic/search
Disallow: /account/
Disallow: /aclick
Disallow: /alink
Disallow: /amp/
...
```

网络蜘蛛/机器人/爬虫可以故意忽略在 ```robots.txt``` 文件中指定的 ```Disallow``` 指令。因此， ```robots.txt``` 不应该被视为一种强制限制第三方如何访问、存储或重新发布web内容的机制。

```robots.txt``` 文件是从web服务器的web根目录中检索的。例如，要使用 ```wget``` 或 ```curl``` 从 ```cn.bing.com``` 中检索 ```robots.txt``` ：

```bash
$ curl -O -s https://cn.bing.com/robots.txt && head robots.txt
User-agent: msnbot-media
Disallow: /
Allow: /th?

User-agent: Twitterbot
Disallow:

User-agent: *
Disallow: /academic/profile
Disallow: /academic/search
```

#### 使用谷歌站长工具分析 robots.txt

网站所有者可以使用谷歌“Analyze robots.txt”功能来分析网站，作为其[谷歌站长工具](https://www.google.com/webmasters/tools)的一部分。该工具可以辅助测试，过程如下：

1. 用谷歌帐户登录谷歌网站管理员工具。
2. 在仪表板上，输入要分析的网站的URL。
3. 选择可用的方法，并遵循屏幕上的说明。

### META 标签

```<META>``` 标签位于每个HTML文档的 ```HEAD``` 部分中，并且应该在整个站点中保持一致，以防机器人/蜘蛛/爬虫的起点是从网站根目录以外的文档链接（即深度链接）开始的情况。机器人指令也可以使用特定的[META标签](https://www.robotstxt.org/meta.html)来指定。

#### Robots META 标签

如果没有 ```<META NAME="ROBOTS" ... >``` 项，则“机器人排除协议”默认分别为 ```INDEX,FOLLOW``` 。因此，“机器人排除协议”定义的其他两个有效条目前缀为 ```NO...``` ，即 ```NOINDEX``` 和 ```NOFOLLOW``` 。

根据 webroot 中的 ```robots.txt``` 文件中列出的 Disallow 指令，对每个网页进行 ```<META NAME="ROBOTS"``` 的正则表达式搜索。然后将结果与 webroot 中的 robots.txt 文件进行比较。

#### 杂项 META 信息标签

网页内容中通常嵌入有信息性 META 标签，以支持各种技术，如屏幕阅读器、社交网络预览、搜索引擎索引等。此类元信息可用来识别使用的技术以及探索和测试的额外路径/功能。以下元信息是通过 2025 年 12 月 23 日的"查看页面源代码"从 ```www.whitehouse.gov``` 获取的：

```html
...
<meta property="og:locale" content="en_US" />
<meta property="og:type" content="website" />
<meta property="og:title" content="The White House" />
<meta property="og:description" content="President Donald J. Trump and Vice President JD Vance are committed to lowering costs for all Americans, securing our borders, unleashing American energy dominance, restoring peace through strength, and making all Americans safe and secure once again." />
<meta property="og:url" content="https://www.whitehouse.gov/" />
<meta property="og:site_name" content="The White House" />
<meta property="article:publisher" content="https://www.facebook.com/WhiteHouse/" />
<meta property="article:modified_time" content="2025-11-19T16:31:23+00:00" />
<meta property="og:image" content="https://www.whitehouse.gov/wp-content/uploads/2025/03/WH47-Social-Share-Card.jpg" />
<meta property="og:image:width" content="1200" />
<meta property="og:image:height" content="628" />
<meta property="og:image:type" content="image/jpeg" />
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:title" content="The White House" />
<meta name="twitter:description" content="President Donald J. Trump and Vice President JD Vance are committed to lowering costs for all Americans, securing our borders, unleashing American energy dominance, restoring peace through strength, and making all Americans safe and secure once again." />
<meta name="twitter:image" content="https://www.whitehouse.gov/wp-content/uploads/2025/03/WH47-Social-Share-Card.jpg" />
<meta name="twitter:site" content="@whitehouse" />
...
<meta name="apple-mobile-web-app-title" content="The White House">
<meta name="application-name" content="The White House">
<meta name="theme-color" content="#f5f5f5">
<meta name="msapplication-TileColor" content="#0D132D" />
<meta name="msapplication-TileImage" content="/wp-content/images/mstile-144x144.png" />
...
```

### Sitemaps

Sitemaps 是一个文件，开发者或组织可在其中提供有关站点或应用程序提供的页面、视频和其他文件的信息，以及它们之间的关系。搜索引擎可以使用此文件更有效地导航站点。同样，测试人员可利用'sitemap.xml'文件，以更深入地了解正在调查的站点或应用程序。

以下摘录来自 2025 年 12 月 23 日检索的 ```bing.com``` 的 sitemap。

```bash
$ wget --no-verbose https://bing.com/sitemap.xml && head sitemap.xml
2025-12-23 13:53:31 URL:https://cn.bing.com/sitemap.xml [1093/1093] -> "sitemap.xml.1" [1]
<?xml version="1.0" encoding="UTF-8"?>
<sitemapindex xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
  <sitemap>
    <loc>https://www.bing.com/home_sitemap.xml</loc>
  </sitemap>
  <sitemap>
    <loc>https://www.bing.com/travelguide/sitemaps/sitemap.xml</loc>
  </sitemap>
  <sitemap>
    <loc>https://www.bing.com/sitemap/shop/sitemap.xml</loc>
```

### Security TXT

[security.txt](https://securitytxt.org/) 由 IETF 作为 [RFC 9116](https://www.rfc-editor.org/rfc/rfc9116.html)（一种用于协助安全漏洞披露的文件格式）正式批准，该文件允许网站定义安全策略和联系方式。在测试场景中，这可能出于多种原因引起兴趣，包括：

- 在发现/分析中确定进一步的路径或资源。
- 开源情报收集。
- 查找有关漏洞悬赏等信息。
- 社会工程学。

该文件可能存在于 Web 服务器的根目录或 .well-known/ 目录中，例如：

- ```https://foo.com/security.txt```
- ```https://foo.com/.well-known/security.txt```

以下是从 Github 2025 年 12 月 23 日获取的一个真实示例：

```bash
$ wget --no-verbose https://github.com/.well-known/security.txt && cat security.txt
2025-12-23 14:35:07 URL:https://github.com/.well-known/security.txt [269/269] -> "security.txt" [1]
Contact: https://hackerone.com/github
Acknowledgments: https://hackerone.com/github/hacktivity
Preferred-Languages: en
Canonical: https://github.com/.well-known/security.txt
Policy: https://bounty.github.com
Hiring: https://github.careers
Expires: 2026-01-22T06:35:07z
```

OpenPGP公钥包含一些可以提供密钥本身信息的元数据。以下是从OpenPGP公钥中提取的一些常见元数据元素：

- Key ID：密钥ID是由公钥材料派生的短标识符。它有助于识别键，通常显示为8个字符的十六进制值。
- Key Fingerprint：密钥指纹是从密钥材料派生出来的更长且更唯一的标识符。它通常显示为40个字符的十六进制值。密钥指纹通常用于验证公钥的完整性和真实性。
- Key Algorithm：密钥算法表示公钥使用的密码算法。OpenPGP支持RSA、DSA、ECC （Elliptic Curve Cryptography）等算法。
- Key Size：密钥长度是指加密密钥的长度或大小，单位为比特。它表示密钥的强度，并决定密钥提供的安全级别。
- Key Creation Date：密钥创建日期，表示密钥生成或创建的时间。
- Key Expiration Date：OpenPGP公钥可以设置过期日期，超过该日期则视为无效。
- User IDs：公钥可以有一个或多个相关联的用户id，用于标识与密钥相关联的所有者或实体。用户id通常包括密钥所有者的姓名、电子邮件地址和可选评论等信息。

### Humans TXT

[humans.txt](https://humanstxt.org/) 是一个了解站点背后的人的倡议。它采用文本文件的形式，其中包含对构建站点做出贡献的不同人员的信息。这个文件通常（但不总是）包含与职业或工作网站/路径相关的信息。

从 ```humanstxt.org``` 2025年12月23日检索到以下示例：

```bash
$ wget --no-verbose  https://humanstxt.org/humans.txt && head humans.txt
2025-12-23 14:56:11 URL:https://humanstxt.org/humans.txt [1587/1587] -> "humans.txt" [1]
/* TEAM */
	Chef:Juanjo Bernabeu
	Contact: hello [at] humanstxt.org
	Twitter: @juanjobernabeu
	From:Barcelona, Catalonia, Spain

	UI developer: Maria Macias
	Twitter: @maria_ux
	From:Barcelona, Catalonia, Spain
```

### 其他 .well-known 信息源

还有其他的rfc和互联网草案建议对 .well-known/ 目录内的文件进行标准化使用。这些列表可以在 [iana.org](https://www.iana.org/assignments/well-known-uris/well-known-uris.xhtml) 找到。

为了验证这些文件的存在或内容，测试人员可相对简单的检查RFC/草案并创建一个列表以提供给爬虫或模糊测试器。

## 工具

- 浏览器（查看源代码或开发者工具功能）
- curl
- wget
- Burp Suite
- ZAP

## 引用

- [WSTG-INFO-03](https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/01-Information_Gathering/03-Review_Webserver_Metafiles_for_Information_Leakage.md#robots-meta-tag)